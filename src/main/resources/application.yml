server:
  port: 9999

xxl:
  job:
    admin:
      ### xxl-job admin address list：调度中心部署跟地址：如调度中心集群部署存在多个地址则用逗号分隔。执行器将会使用该地址进行"执行器心跳注册"和"任务结果回调"。
      addresses: http://127.0.0.1:8080/xxl-job-admin-1.9.1
    executor:
      ### xxl-job executor address：执行器"AppName"和地址信息配置：AppName执行器心跳注册分组依据；地址信息用于"调度中心请求并触发任务"和"执行器注册"。
      ### 执行器默认端口为9999，执行器IP默认为空表示自动获取IP，多网卡时可手动设置指定IP，手动设置IP时将会绑定Host。单机部署多个执行器时，注意要配置不同执行器端口；
      appName: my-xxl-job-executor
      ip:
      port: 8889
      ### xxl-job log path：执行器运行日志文件存储的磁盘位置，需要对该路径拥有读写权限
      logPath: /data/applogs/xxl-job/jobhandler
      ### xxl-job log retention days：执行器Log文件定期清理功能，指定日志保存天数，日志文件过期自动删除。限制至少保持3天，否则功能不生效；
      logRetentionDays: -1
    ### xxl-job, access token：执行器通讯TOKEN，非空时启用
    accessToken:

spring:
  application:
    name: clean-data
  kafka:
    bootstrap-servers: 172.30.34.40:9092,172.30.34.41:9092
    #    bootstrap-servers: localhost:9092
    client-id: column-check
    consumer:
      group-id: column-check-group
    producer:
      compression-type: gzip
  data:
    mongodb:
      uri: mongodb://192.168.10.144:27000/bigdata
    redis:
      clusterNodes: 172.30.34.3:7000,172.30.34.3:7001,172.30.34.3:7002,172.30.34.3:7003,172.30.34.3:7004,172.30.34.3:7005
      commandTimeout: 10000
      expireSeconds: 7200
  datasource:
    driver-class-name: oracle.jdbc.driver.OracleDriver
    url: jdbc:oracle:thin:@172.30.35.100:1521:orcl
    username: bigdat
    password: bigdat
  #      maxWait: 60000
  #      timeBetweenEvictionRunsMillis: 60000
  #      initialSize: 2
  #      minIdle: 2
  #      maxActive: 50
  #      removeAbandoned: true
  #      removeAbandonedTimeout : 1000
  jpa:
    show-sql: false
    database-platform: org.hibernate.dialect.MySQL5Dialect
    hibernate:
      ddl-auto: none
    database: oracle
    properties:
      hibernate:
        jdbc:
          batch_size: 10000
logging:
  level:
#    org.apache.spark.rdd: off  #指定包的日志输出级别
    root: info
  pattern:
    console: '%d{yyyy/MM/dd-HH:mm:ss} [%thread] %-5level %logger- %msg%n'

kafka:
  consumer:
    fechSize: 10000
    concurrency: 10
    statisticFechSize: 200000
